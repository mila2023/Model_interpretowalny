{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score, classification_report, confusion_matrix, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fb2d7a",
   "metadata": {},
   "source": [
    "---\n",
    "## `PKDKodWoEEncoder` (Weight of Evidence Encoder)\n",
    "\n",
    "Klasa transformująca zmienną kategoryczną 'pkdKod' na miarę Weight of Evidence (WoE). Służy do przygotowania zmiennych kategorycznych o dużej liczbie unikalnych wartości dla modeli scoringowych.\n",
    "\n",
    "---\n",
    "\n",
    "### **Działanie Kluczowe**\n",
    "* Grupowanie Rzadkich Kategorii: Identyfikuje top_n najczęściej występujących kategorii. Wszystkie pozostałe kategorie (rzadkie) są grupowane w jedną kategorię oznaczoną jako '0'.\n",
    "\n",
    "* Obliczanie WoE: Dla każdej z topowych kategorii i kategorii '0' oblicza WoE. WoE jest logarytmem naturalnym z ilorazu szans (Good/Bad) w danej grupie, podzielonego przez iloraz szans w całej próbie (Good_Total/Bad_Total).\n",
    "\n",
    "$$WoE = \\ln \\left( \\frac{P(\\text{Good} | \\text{Grupa})}{P(\\text{Bad} | \\text{Grupa})} / \\frac{P(\\text{Good Total})}{P(\\text{Bad Total})} \\right)$$\n",
    "\n",
    "* Wygładzanie (Smoothing): Dodaje wartość smoothing (np. 0.5) do liczebności zdarzeń \"Good\" i \"Bad\" (dobrych i złych), aby uniknąć dzielenia przez zero i zmniejszyć wpływ małych prób.\n",
    "\n",
    "* Transformacja: Zastępuje wartość pkdKod obliczoną wartością WoE. Oryginalna kolumna pkdKod jest usuwana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PKDKodWoEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, top_n=10, smoothing=0.5):\n",
    "        self.top_n = top_n\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        \n",
    "        self.top_values_ = X['pkdKod'].value_counts().nlargest(self.top_n).index\n",
    "        \n",
    "        grouped = X['pkdKod'].where(X['pkdKod'].isin(self.top_values_), other='0')\n",
    "        \n",
    "        df = pd.DataFrame({'group': grouped, 'target': y})\n",
    "        agg = df.groupby('group')['target'].agg(['sum', 'count'])\n",
    "        agg = agg.rename(columns={'sum':'bad', 'count':'total'})\n",
    "        agg['good'] = agg['total'] - agg['bad']\n",
    "\n",
    "        agg['bad_s'] = agg['bad'] + self.smoothing\n",
    "        agg['good_s'] = agg['good'] + self.smoothing\n",
    "\n",
    "        total_bad = agg['bad_s'].sum()\n",
    "        total_good = agg['good_s'].sum()\n",
    "\n",
    "        agg['woe'] = np.log((agg['good_s'] / total_good) / (agg['bad_s'] / total_bad))\n",
    "\n",
    "        self.woe_map_ = agg['woe'].to_dict()\n",
    "        self.fallback_ = agg.loc['0', 'woe'] if '0' in agg.index else np.mean(list(self.woe_map_.values()))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        grouped = X['pkdKod'].where(X['pkdKod'].isin(self.top_values_), other='0')\n",
    "        X['WoE_pkdKod_grouped'] = grouped.map(self.woe_map_).fillna(self.fallback_)\n",
    "        return X.drop(columns=['pkdKod'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debc8d0b",
   "metadata": {},
   "source": [
    "---\n",
    "## `DropConstantColumns` (Usuwanie stałych kolumn)\n",
    "\n",
    "Prosty transformator, którego zadaniem jest identyfikacja i usunięcie z ramki danych kolumn, które mają **jedną lub zero unikalnych wartości** (są stałe).\n",
    "\n",
    "---\n",
    "\n",
    "### **Działanie Kluczowe**\n",
    "\n",
    "* Fit: W fazie treningu (fit) identyfikuje kolumny, w których liczba unikalnych wartości (nunique()) jest mniejsza lub równa 1. Nazwy tych kolumn są przechowywane w self.cols_to_drop_.\n",
    "* Transform: W fazie transformacji (transform) usuwa te zidentyfikowane kolumny z ramki danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropConstantColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.cols_to_drop_ = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.cols_to_drop_, errors='ignore')\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None:\n",
    "             raise ValueError(\"input_features nie może być None dla DropConstantColumns\")\n",
    "        return [col for col in input_features if col not in self.cols_to_drop_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7f9d3",
   "metadata": {},
   "source": [
    "---\n",
    "## `MissingValueIndicatorAndImputer`\n",
    "\n",
    "Ta klasa jest transformatorem scikit-learn, który realizuje dwie operacje jednocześnie na kolumnach numerycznych: imputację brakujących wartości oraz tworzenie kolumn-wskaźników braków danych.\n",
    "\n",
    "---\n",
    "\n",
    "### **Działanie Kluczowe**\n",
    "\n",
    "* Obsługa Nieskończoności: Zamienia wartości nieskończone (np.inf, -np.inf) na braki danych (np.nan).\n",
    "* Imputacja: Wykorzystuje SimpleImputer (strategia domyślna to mediana, ale można zmienić np. na mean lub most_frequent) do zastąpienia brakujących wartości. W fazie fit uczy się wartości imputacji, a w transform je stosuje.\n",
    "\n",
    "* Wskaźnik Braków Danych: Tworzy nową kolumnę dla każdej oryginalnej kolumny, której nazwa kończy się na _mial_braki_danych. Wartość w tej kolumnie wynosi 1, jeśli oryginalna kolumna miała brak danych, i 0 w przeciwnym razie.\n",
    "\n",
    "* Łączenie: Zwraca ramkę danych zawierającą zaimputowane oryginalne kolumny oraz nowo utworzone kolumny-wskaźniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueIndicatorAndImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy=\"median\"):\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).copy()\n",
    "        self.base_cols_ = list(X.columns)\n",
    "\n",
    "        self.imputer_ = SimpleImputer(strategy=self.strategy)\n",
    "        self.imputer_.fit(X[self.base_cols_])\n",
    "\n",
    "        self.indicator_cols_ = [f\"{c}_mial_braki_danych\" for c in self.base_cols_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).copy()\n",
    "\n",
    "        X_imputed = pd.DataFrame(\n",
    "            self.imputer_.transform(X[self.base_cols_]),\n",
    "            columns=self.base_cols_,\n",
    "            index=X.index\n",
    "        )\n",
    "\n",
    "        indicator_df = X[self.base_cols_].isna().astype(int)\n",
    "        indicator_df.columns = self.indicator_cols_\n",
    "        indicator_df.index = X.index\n",
    "\n",
    "        X_out = pd.concat([X_imputed, indicator_df], axis=1)\n",
    "\n",
    "        return X_out\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "            base_cols = self.base_cols_\n",
    "            indicator_cols = self.indicator_cols_\n",
    "            return base_cols + indicator_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da1ea0",
   "metadata": {},
   "source": [
    "---\n",
    "## `Podział Danych na Zbiory` Treningowy, Walidacyjny, Testowy\n",
    "\n",
    "---\n",
    "\n",
    "Treningowy (Train): Używany do uczenia modelu.\n",
    "\n",
    "Walidacyjny (Validation/Val): Używany do strojenia hiperparametrów i wczesnego zatrzymywania treningu (early stopping).\n",
    "\n",
    "Testowy (Test): Używany do ostatecznej, niezależnej oceny wydajności gotowego modelu.\n",
    "\n",
    "Użyto dwóch kroków podziału, aby uzyskać proporcje około 70% / 15% / 15% (Train / Val / Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515336b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych\n",
    "data = pd.read_csv(\"zbiór_10.csv\")\n",
    "\n",
    "# Definicja cech X i y\n",
    "X = data.drop(columns=[\"default\"])\n",
    "y = data[\"default\"]\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.18, random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22e3ce",
   "metadata": {},
   "source": [
    "---\n",
    "## `Kodowanie WoE dla Kolumny pkdKod`\n",
    "\n",
    "---\n",
    "\n",
    "Ten proces demonstruje kluczową technikę w pre-processingu danych, jaką jest kodowanie Weight of Evidence (WoE), stosowaną na zmiennej kategorycznej pkdKod. Najważniejszą zasadą jest dopasowanie (fit) transformatora wyłącznie do danych treningowych, aby zapewnić, że wiedza o rozkładzie targetu (y) w kategoriach nie wycieknie do zbiorów walidacyjnych i testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting WoE Encoder...\")\n",
    "woe_encoder = PKDKodWoEEncoder(top_n=10, smoothing=0.5)\n",
    "\n",
    "woe_encoder.fit(X_train, y_train)\n",
    "\n",
    "X_train_woe = woe_encoder.transform(X_train)\n",
    "X_val_woe = woe_encoder.transform(X_val)\n",
    "X_test_woe = woe_encoder.transform(X_test)\n",
    "\n",
    "print(\"WoE encoding complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661adc2d",
   "metadata": {},
   "source": [
    "---\n",
    "## `Budowa Pipeline'u Preprocessingowego`\n",
    "\n",
    "---\n",
    "\n",
    "Poniższy opis definiuje kompleksowy potok (Pipeline) do automatycznego przetwarzania różnych typów cech w zbiorze danych. Użycie ColumnTransformer pozwala na jednoczesne stosowanie różnych transformatorów do cech numerycznych i kategorycznych.\n",
    "\n",
    "---\n",
    "### **Definicja Cech**\n",
    "\n",
    "Po wstępnym kodowaniu WoE kolumny pkdKod, pozostałe kolumny są dzielone na numeryczne i kategoryczne (te, które będą kodowane One-Hot Encodingiem - OHE).\n",
    "\n",
    "* Cechy Kategoryczne (do OHE): formaWlasnosci_Symbol, schemat_wsk_bilans, schemat_wsk_rzis.\n",
    "\n",
    "* Cechy Numeryczne: Wszystkie pozostałe kolumny (włączając już przetworzoną cechę WoE).\n",
    "\n",
    "### **Potok Cech Numerycznych**\n",
    "\n",
    "Potok dla cech numerycznych jest sekwencją trzech kroków transformacji:\n",
    "\n",
    "* Imputacja i Wskaźnik Braków (MissingValueIndicatorAndImputer): Wypełnienie brakujących wartości (mediana) oraz utworzenie pomocniczych kolumn binarnych sygnalizujących, gdzie pierwotnie wystąpił brak danych.\n",
    "\n",
    "* Usunięcie Stałych Kolumn (DropConstantColumns): Identyfikacja i usunięcie cech, które po imputacji (lub z natury) mają jedną lub zero unikalnych wartości.\n",
    "\n",
    "* Skalowanie (StandardScaler): Standaryzacja pozostałych cech numerycznych (przesunięcie do średniej 0 i skalowanie do odchylenia standardowego 1).\n",
    "\n",
    "### **Potok Cech Kategorycznych**\n",
    "\n",
    "Potok ten stosuje One-Hot Encoding (OneHotEncoder) do wcześniej zdefiniowanych cech kategorycznych. Opcja ignorowania nieznanych kategorii (handle_unknown='ignore') jest kluczowa, aby uniknąć błędów, jeśli w zbiorze walidacyjnym lub testowym pojawi się kategoria nieobecna w danych treningowych.\n",
    "\n",
    "### **ColumnTransformer**\n",
    "\n",
    "ColumnTransformer łączy oba potoki, stosując je do odpowiednich list cech. Cechy numeryczne trafiają do numeric_transformer, a kategoryczne do categorical_transformer. Opcja remainder='passthrough' jest ustawiona, by zapewnić, że wszystkie kolumny, które nie zostały objęte żadnym z potoków, zostaną włączone do wyjściowego zbioru danych bez zmian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8103c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'formaWlasnosci_Symbol', \n",
    "    'schemat_wsk_bilans', \n",
    "    'schemat_wsk_rzis'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    col for col in X_train_woe.columns if col not in categorical_features\n",
    "]\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('missing', MissingValueIndicatorAndImputer(strategy=\"median\")),\n",
    "    ('drop_constant', DropConstantColumns()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e3212",
   "metadata": {},
   "source": [
    "---\n",
    "## `Finalny Potok Modelowania z XGBoost`\n",
    "\n",
    "---\n",
    "\n",
    "Ten kod definiuje kompletny potok modelowania (Pipeline), który integruje wszystkie wcześniej zdefiniowane kroki przetwarzania danych (preprocessor) z modelem XGBoost Classifier. Jest to standardowa i zalecana praktyka w uczeniu maszynowym, która zapewnia, że procesy pre-processingu są stosowane konsekwentnie podczas treningu, walidacji i testowania.\n",
    "\n",
    "Obiekt pipeline jest teraz gotowy do dopasowania do danych treningowych (pipeline.fit(X_train, y_train)). Używając tego potoku, zapewniamy, że podczas treningu i predykcji wszystkie dane przechodzą przez identyczną sekwencję transformacji, co jest niezbędne dla rzetelności modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61690a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42,\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum() \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec93621",
   "metadata": {},
   "source": [
    "---\n",
    "## `Eksport Wytrenowanego Pipeline'u do Pliku PKL`\n",
    "\n",
    "---\n",
    "\n",
    "Po wytrenowaniu modelu, konieczne jest zapisanie całego obiektu pipeline (zawierającego zarówno transformacje, jak i model XGBoost) do pliku. Używamy do tego biblioteki joblib, która jest wydajna przy dużych obiektach, takich jak modele scikit-learn i pipeline'y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_processed = pipeline['preprocessor'].fit(X_train_woe).transform(X_val_woe)\n",
    "\n",
    "fit_params = {\n",
    "    'model__eval_set': [(X_val_processed, y_val)],\n",
    "    'model__verbose' : 100\n",
    "}\n",
    "\n",
    "pipeline.fit(X_train_woe, y_train, **fit_params)\n",
    "\n",
    "joblib.dump(pipeline, 'XGBoost_model_pipeline.pkl')\n",
    "\n",
    "print(\"Pipeline training complete.\")\n",
    "print(\"Model was successfully exported to file 'XGBoost_model_pipeline.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65351673",
   "metadata": {},
   "source": [
    "---\n",
    "## `Przygotowanie Danych do Analizy SHAP`\n",
    "\n",
    "---\n",
    "\n",
    "Poniższy kod służy do przygotowania przekształconych danych testowych do późniejszej analizy, np. za pomocą biblioteki SHAP (SHapley Additive exPlanations), która pomaga w interpretacji wyników modelu uczenia maszynowego.\n",
    "\n",
    "* Najpierw kod wydobywa dwa kluczowe elementy ze zdefiniowanego wcześniej obiektu pipeline. \n",
    "* Kod próbuje pobrać nazwy cech po ich przekształceniu przez preprocesor. Jest to kluczowe dla interpretowalności, ponieważ przekształcone cechy mogą mieć inne nazwy niż oryginalne.\n",
    "* Następnie dane testowe X_test_woe są poddawane końcowej transformacji przez wyodrębniony preprocesor.\n",
    "* Przekształcone dane w postaci tablicy NumPy są konwertowane z powrotem na DataFrame biblioteki pandas, co jest wygodne do dalszej analizy i interpretacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = pipeline.named_steps['preprocessor']\n",
    "model = pipeline.named_steps['model']\n",
    "\n",
    "try:\n",
    "    final_feature_names = preprocessor.get_feature_names_out()\n",
    "    print(f\"Pobrano {len(final_feature_names)} finalnych nazw cech.\")\n",
    "except Exception as e:\n",
    "    print(f\"Błąd przy get_feature_names_out: {e}\")\n",
    "\n",
    "X_test_transformed_np = preprocessor.transform(X_test_woe)\n",
    "\n",
    "X_test_transformed_df = pd.DataFrame(\n",
    "    X_test_transformed_np, \n",
    "    columns=final_feature_names, \n",
    "    index=X_test_woe.index\n",
    ")\n",
    "\n",
    "print(\"Dane dla SHAP przygotowane.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a13ec",
   "metadata": {},
   "source": [
    "---\n",
    "## `Obliczanie Wartości SHAP i Ustalanie Wartości Bazowej`\n",
    "\n",
    "---\n",
    "\n",
    "Poniższy kod służy do przygotowania przekształconych danych testowych do późniejszej analizy, np. za pomocą biblioteki SHAP (SHapley Additive exPlanations), która pomaga w interpretacji wyników modelu uczenia maszynowego.\n",
    "\n",
    "* Inicjalizowany jest obiekt shap.TreeExplainer, który jest zoptymalizowany do interpretacji modeli bazujących na drzewach decyzyjnych.\n",
    "* Następuje obliczenie wartości SHAP dla całego zbioru danych testowych X_test_transformed_df.\n",
    "* Ostatecznie drukowana jest Wartość Bazowa, która jest wartością log-odds średniej przewidywanej przez model. Reprezentuje ona wynik modelu, gdybyśmy nie znali żadnych cech dla danej instancji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24206c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "print(\"Obliczanie wartości SHAP...\")\n",
    "shap_values_all_classes = explainer(X_test_transformed_df)\n",
    "print(\"Wartości SHAP obliczone.\")\n",
    "\n",
    "shap_values = shap_values_all_classes\n",
    "baseline = float(shap_values_all_classes.base_values[0])\n",
    "\n",
    "print(f\"Baseline (wartość bazowa log-odds): {baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5acaf9",
   "metadata": {},
   "source": [
    "---\n",
    "## `Weryfikacja Spójności Analizy SHAP`\n",
    "\n",
    "---\n",
    "\n",
    "Ten kod służy do przeprowadzenia weryfikacji i sprawdzenia, czy obliczone wartości SHAP są spójne z surową predykcją modelu dla konkretnej, pojedynczej obserwacji.\n",
    "\n",
    "* Wybrana zostaje pierwsza obserwacja.\n",
    "* Model dokonuje surowej predykcji dla tej jednej obserwacji.\n",
    "* Zgodnie z teorią SHAP, suma wartości bazowej i wszystkich wartości SHAP dla danej obserwacji musi być równa surowej predykcji modelu dla tej obserwacji:\n",
    "$$\\text{Baseline} + \\sum (\\text{Wartości SHAP}) \\approx \\text{Surowa Predykcja (log-odds)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "obserwacja_idx = X_test_transformed_df.index[idx]\n",
    "przetworzone_dane_obs = X_test_transformed_df.iloc[[idx]]\n",
    "\n",
    "shap_sum = float(shap_values.values[idx].sum())\n",
    "\n",
    "raw_prediction = model.predict(przetworzone_dane_obs, output_margin=True)[0]\n",
    "\n",
    "print(\"\\nWeryfikacja dla pierwszej obserwacji testowej:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Baseline (wartość bazowa):         {baseline:.4f}\")\n",
    "print(f\"Suma wartości SHAP:                {shap_sum:+.4f}\")\n",
    "print(f\"Baseline + Suma SHAP:              {baseline + shap_sum:.4f}\")\n",
    "print(f\"Surowa predykcja modelu (log-odds): {raw_prediction:.4f}\")\n",
    "\n",
    "if abs((baseline + shap_sum) - raw_prediction) < 1e-5:\n",
    "    print(\"\\nWeryfikacja: Wyjaśnienia są spójne z modelem.\")\n",
    "else:\n",
    "    print(\"\\nWeryfikacja: Wyjaśnienia NIE są spójne z modelem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dea0c2",
   "metadata": {},
   "source": [
    "---\n",
    "## `Globalna Ważność Cech (Wykres Beeswarm)`\n",
    "\n",
    "---\n",
    "\n",
    "Wykres ten dostarcza globalnego podsumowania wyników interpretacji modelu.\n",
    "\n",
    "* Wizualizacja: Na wykresie każda kropka reprezentuje pojedynczą obserwację i jej wpływ SHAP dla danej cechy.\n",
    "\n",
    "* Pozycja: Odległość kropki od środka (wartości SHAP równej zero) wskazuje na wielkość wpływu cechy na predykcję.\n",
    "\n",
    "* Kolor: Kolor kropki najczęściej wskazuje na wartość cechy (np. czerwony = wysoka wartość cechy, niebieski = niska wartość cechy).\n",
    "\n",
    "W efekcie, wykres ten nie tylko pokazuje, które cechy są najważniejsze (znajdują się na szczycie listy), ale także kierunek i rozrzut ich wpływu na predykcję (pozytywny czy negatywny) w całym zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf638ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Globalna ważność cech (Beeswarm):\")\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_transformed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d42317",
   "metadata": {},
   "source": [
    "---\n",
    "## `Wykres Zależności SHAP (Dependence Plot)`\n",
    "\n",
    "---\n",
    "\n",
    "Te bloki kodu służą do wizualizacji konkretnego wpływu pojedynczych cech na predykcję modelu oraz identyfikację potencjalnej interakcji tych cech z innymi. Wybrano do tego 5 najbardziej wpływowych cech:\n",
    "\n",
    "* num__wsk_poziom_kapitalu_obrotowego_netto\n",
    "\n",
    "* num__Kapital_wlasny\n",
    "\n",
    "* num__zysk_netto\n",
    "\n",
    "* num__wsk_cykl_konwersji_gotowki\n",
    "\n",
    "* num__wsk_sprzedaz_kap_obrotowy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0327fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CECHA = 'num__wsk_poziom_kapitalu_obrotowego_netto'\n",
    "\n",
    "print(f\"Wykres zależności dla: {CECHA}\")\n",
    "\n",
    "shap.dependence_plot(\n",
    "    CECHA,\n",
    "    shap_values.values,\n",
    "    X_test_transformed_df,\n",
    "    interaction_index=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CECHA = 'num__Kapital_wlasny'\n",
    "\n",
    "print(f\"Wykres zależności dla: {CECHA}\")\n",
    "\n",
    "shap.dependence_plot(\n",
    "    CECHA,\n",
    "    shap_values.values,\n",
    "    X_test_transformed_df,\n",
    "    interaction_index=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CECHA = 'num__zysk_netto'\n",
    "\n",
    "print(f\"Wykres zależności dla: {CECHA}\")\n",
    "\n",
    "shap.dependence_plot(\n",
    "    CECHA,\n",
    "    shap_values.values,\n",
    "    X_test_transformed_df,\n",
    "    interaction_index=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CECHA = 'num__wsk_cykl_konwersji_gotowki'\n",
    "\n",
    "print(f\"Wykres zależności dla: {CECHA}\")\n",
    "\n",
    "shap.dependence_plot(\n",
    "    CECHA,\n",
    "    shap_values.values,\n",
    "    X_test_transformed_df,\n",
    "    interaction_index=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5891a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "CECHA = 'num__wsk_sprzedaz_kap_obrotowy'\n",
    "\n",
    "print(f\"Wykres zależności dla: {CECHA}\")\n",
    "\n",
    "shap.dependence_plot(\n",
    "    CECHA,\n",
    "    shap_values.values,\n",
    "    X_test_transformed_df,\n",
    "    interaction_index=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64173f",
   "metadata": {},
   "source": [
    "---\n",
    "## `Optymalizacja Progu Decyzyjnego i Ocena Modelu`\n",
    "\n",
    "---\n",
    "\n",
    "Tutaj koncentrujemy się na znalezieniu optymalnego progu decyzyjnego dla modelu klasyfikacji binarnej, a następnie na dokładnej ocenie modelu przy użyciu tego nowego progu.\n",
    "\n",
    "* Prawdopodobieństwa: Najpierw pobierane są prawdopodobieństwa przynależności do y_proba z wytrenowanego pipeline.\n",
    "\n",
    "* Krzywa Precision-Recall: Obliczane są precision i recall dla różnych możliwych progów decyzyjnych.\n",
    "\n",
    "* Wykres: Generowany jest wykres zależności precision i recall od progu, co wizualnie pomaga zrozumieć kompromis między tymi metrykami.\n",
    "\n",
    "* Wybór Optymalnego Progu: Optymalny próg jest wybierany na podstawie maksymalizacji miary F1-Score (średnia harmoniczna precision i recall), co zazwyczaj zapewnia najlepszą równowagę między błędami typu I i II.\n",
    "\n",
    "* Predykcja: Na podstawie znalezionego best_threshold generowane są ostateczne predykcje binarne (y_pred_best).\n",
    "\n",
    "* Metryki Modelu: Wyświetlana jest Dokładność (Accuracy) osiągnięta przy nowym progu oraz najlepsze parametry (numer iteracji, wynik walidacji) z samego procesu trenowania modelu.\n",
    "\n",
    "* Classification Report: Wyświetlany jest szczegółowy raport klasyfikacji, zawierający Precyzję, Czułość i F1-Score dla każdej klasy (No Default i Default).\n",
    "\n",
    "* Confusion Matrix: Obliczana i drukowana jest macierz pomyłek, która pokazuje True Positives/Negatives, False Positives/Negatives.\n",
    "\n",
    "* Wizualizacja Macierzy: Macierz pomyłek jest wizualizowana jako mapa ciepła (heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74826a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = pipeline.predict_proba(X_test_woe)[:, 1]\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba, pos_label=1)\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision & Recall vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "f1_scores = (2 * precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-10)\n",
    "\n",
    "best_f1_index = np.argmax(f1_scores)\n",
    "\n",
    "best_threshold = thresholds[best_f1_index]\n",
    "best_f1_score = f1_scores[best_f1_index]\n",
    "\n",
    "print(f\"\\n--- Optimal Threshold Finder ---\")\n",
    "print(f\"Best F1-Score: {best_f1_score:.4f}\")\n",
    "print(f\"Found at Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "y_pred_best = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Best Iteration: {pipeline.named_steps['model'].best_iteration}\")\n",
    "print(f\"Best Score (Validation AUC): {pipeline.named_steps['model'].best_score:.4f}\")\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "print(f\"\\n--- Classification Report (Threshold = {best_threshold:.4f}) ---\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['No Default (0)', 'Default (1)']))\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "print(\"--- Confusion Matrix (Threshold = {best_threshold:.4f}) ---\")\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(cm)\n",
    "\n",
    "# -----------------------\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted: No Default', 'Predicted: Default'], \n",
    "            yticklabels=['Actual: No Default', 'Actual: Default'])\n",
    "plt.title(f'Confusion Matrix (Threshold = {best_threshold:.4f})')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34afdc",
   "metadata": {},
   "source": [
    "---\n",
    "## `Analiza Przypadku False Negative`\n",
    "\n",
    "---\n",
    "\n",
    "Ten kod ma na celu wyjaśnienie najgroźniejszego rodzaju błędu modelu w klasyfikacji ryzyka: False Negative (FN). FN to klienci, którzy w rzeczywistości ogłosili niewypłacalność (Actual = 1), ale model błędnie przewidział, że są bezpieczni (Predicted = 0).\n",
    "\n",
    "Wykres wizualnie pokazuje cechy o dodatnim wpływie pchające predykcję w górę i cechy o ujemnym wpływie pchające predykcję w dół."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_indices = X_test_woe[(y_pred_best == 0) & (y_test == 1)].index\n",
    "\n",
    "if not fn_indices.empty:\n",
    "\n",
    "    idx_to_explain = fn_indices[1] \n",
    "    \n",
    "    idx_position = X_test_transformed_df.index.get_loc(idx_to_explain)\n",
    "\n",
    "    print(f\"\\n--- Wyjaśnienie dla obserwacji FALSE NEGATIVE (Indeks: {idx_to_explain}) ---\")\n",
    "    \n",
    "    shap.plots.waterfall(shap_values[idx_position])\n",
    "    \n",
    "else:\n",
    "    print(\"Gratulacje, brak pomyłek False Negative do analizy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69799752",
   "metadata": {},
   "source": [
    "---\n",
    "## `Analiza Cech Właściwych dla Błędów False Negative`\n",
    "\n",
    "---\n",
    "\n",
    "Ten kod ma na celu izolację i wizualizację statystycznego wpływu cech wyłącznie dla grupy obserwacji sklasyfikowanych jako False Negative (FN). Pokazuje, dlaczego ten konkretny podzbiór klientów, mimo że w rzeczywistości ryzykowny, został uznany przez model za bezpieczny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_indices = X_test_woe[(y_pred_best == 0) & (y_test == 1)].index\n",
    "\n",
    "if not fn_indices.empty:\n",
    "    print(f\"Analizuję {len(fn_indices)} przypadków False Negative...\")\n",
    "    \n",
    "    fn_positions = X_test_transformed_df.index.get_indexer(fn_indices)\n",
    "    \n",
    "    fn_positions = fn_positions[fn_positions != -1]\n",
    "\n",
    "    print(\"Generuję wykres 'summary_plot' tylko dla przypadków FN:\")\n",
    "    \n",
    "    shap.summary_plot(\n",
    "        shap_values[fn_positions], \n",
    "        X_test_transformed_df.iloc[fn_positions]\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"Brak pomyłek False Negative do analizy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba56bb",
   "metadata": {},
   "source": [
    "---\n",
    "## `Analiza Kalibracji Modelu`\n",
    "\n",
    "---\n",
    "\n",
    "1. expected_calibration_error: oblicza Błąd Oczekiwanej Kalibracji (ECE) dla modelu klasyfikacji.\n",
    "\n",
    "2. reliability_plot: generuje Wykres Wiarygodności (Reliability Plot), zwany też krzywą kalibracji.\n",
    "\n",
    "3. hist_predictions: generuje histogram prognozowanych prawdopodobieństw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca8357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_calibration_error(y_true, p, n_bins=10):\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        mask = (p >= bins[i]) & (p < bins[i+1])\n",
    "        if mask.any():\n",
    "            conf = p[mask].mean()\n",
    "            acc = y_true[mask].mean()\n",
    "            ece += (mask.sum()/len(p)) * abs(acc - conf)\n",
    "    return ece\n",
    "\n",
    "def reliability_plot(y_true, p, title):\n",
    "\n",
    "    frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10, strategy='uniform')\n",
    "    \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.plot([0,1],[0,1], '--', label='Perfekcyjna kalibracja')\n",
    "    plt.plot(mean_pred, frac_pos, marker='o', label='Model XGBoost')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Średnia prognozowana PD (Pewność)\")\n",
    "    plt.ylabel(\"Rzeczywista częstość zdarzeń (Celność)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def hist_predictions(p, title):\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.hist(p, bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Prognozowane Prawdopodobieństwo (PD)\")\n",
    "    plt.ylabel(\"Liczność obserwacji\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"---  DIAGNOSTYKA MODELU (PRE-CALIBRATION) ---\")\n",
    "\n",
    "reliability_plot(y_test, y_proba, \"Krzywa Reliability — Model XGBoost (Test, pre-cal)\")\n",
    "\n",
    "hist_predictions(y_proba, \"Histogram Predykcji — Model XGBoost (Test, pre-cal)\")\n",
    "\n",
    "ece_pre = expected_calibration_error(y_test, y_proba, n_bins=10)\n",
    "brier_pre = brier_score_loss(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nWyniki (pre-cal):\")\n",
    "print(f\"  Oczekiwany Błąd Kalibracji (ECE): {ece_pre:.4f}\")\n",
    "print(f\"  Wynik Briera (Brier Score):       {brier_pre:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16218a74",
   "metadata": {},
   "source": [
    "---\n",
    "## `Funkcje Kalibracji Modelu (Platt i Isotonic)`\n",
    "\n",
    "---\n",
    "\n",
    "Poniższy kod definiuje funkcje przeznaczone do kalibracji prognoz prawdopodobieństwa modelu, co jest procesem dostosowywania niekalibrowanych wyjść w celu uzyskania bardziej wiarygodnych i dokładnych prawdopodobieństw. Porównujemy skuteczność metody Platt'a i Izotonicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_platt(y, p):\n",
    "    eps = 1e-12\n",
    "    logit = np.log(np.clip(p, eps, 1-eps) / np.clip(1-p, eps, 1-eps))\n",
    "    lr = LogisticRegression(max_iter=500, C=1e6) \n",
    "    lr.fit(logit.reshape(-1,1), y)\n",
    "    return lr\n",
    "\n",
    "def apply_platt(lr, p):\n",
    "    eps = 1e-12\n",
    "    logit = np.log(np.clip(p, eps, 1-eps) / np.clip(1-p, eps, 1-eps))\n",
    "    return lr.predict_proba(logit.reshape(-1,1))[:,1]\n",
    "\n",
    "def fit_isotonic(y, p):\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    ir.fit(p, y)\n",
    "    return ir\n",
    "\n",
    "def apply_isotonic(ir, p):\n",
    "    return ir.transform(p)\n",
    "\n",
    "\n",
    "print(\"Obliczanie prognoz dla zbioru walidacyjnego...\")\n",
    "y_proba_val = pipeline.predict_proba(X_val_woe)[:, 1]\n",
    "\n",
    "y_proba_test_pre_cal = y_proba \n",
    "\n",
    "print(\"Dopasowywanie kalibratorów na zbiorze walidacyjnym...\")\n",
    "platt_model = fit_platt(y_val, y_proba_val)\n",
    "iso_model = fit_isotonic(y_val, y_proba_val)\n",
    "print(\"Kalibratory wytrenowane.\")\n",
    "\n",
    "print(\"Stosowanie kalibratorów na zbiorze testowym...\")\n",
    "y_proba_test_platt = apply_platt(platt_model, y_proba_test_pre_cal)\n",
    "y_proba_test_iso   = apply_isotonic(iso_model, y_proba_test_pre_cal)\n",
    "\n",
    "print(\"\\n--- OCENA (POST-CALIBRATION) ---\")\n",
    "\n",
    "calibrated_probas = {\n",
    "    'Platt': y_proba_test_platt,\n",
    "    'Isotonic': y_proba_test_iso\n",
    "}\n",
    "\n",
    "for name, p in calibrated_probas.items():\n",
    "    print(f\"\\n--- Model: {name} (post-cal) ---\")\n",
    "            \n",
    "    reliability_plot(y_test, p, f\"Reliability — {name} (test, post-cal)\")\n",
    "    hist_predictions(p, f\"Histogram predykcji — {name} (test, post-cal)\")\n",
    "    \n",
    "    ece_post = expected_calibration_error(y_test, p, n_bins=10)\n",
    "    brier_post = brier_score_loss(y_test, p)\n",
    "    \n",
    "    print(f\"Wyniki dla {name} (post-cal):\")\n",
    "    print(f\"  Oczekiwany Błąd Kalibracji (ECE): {ece_post:.4f}\")\n",
    "    print(f\"  Wynik Briera (Brier Score):       {brier_post:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfbb087",
   "metadata": {},
   "source": [
    "---\n",
    "## `Funkcje Transformacji Logit i Dopasowania Średniej`\n",
    "\n",
    "---\n",
    "\n",
    "Ten zestaw funkcji służy do zaawansowanej manipulacji prawdopodobieństwami wyjściowymi modelu, wykorzystując skalę log-odds (logit) do precyzyjnego dopasowania średniej prognozowanego ryzyka do z góry określonej docelowej stopy ryzyka.\n",
    "\n",
    "* logit_fn: konwersja prawdopodobieństwa P na log-odds.\n",
    "\n",
    "* inv_logit: konwersja log-odds z powrotem na prawdopodobieństwo P.\n",
    "\n",
    "* shift_to_target_mean: dostosowanie wszystkich prognoz prawdopodobieństwa w taki sposób, aby ich średnia była równa z góry ustalonej wartości target_mean (np. u nas 4% ryzyka)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea04ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_fn(p, eps=1e-12):\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def inv_logit(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def shift_to_target_mean(p, target_mean=0.04, tol=1e-6, max_iter=100):\n",
    "    \n",
    "    z = logit_fn(p)\n",
    "    \n",
    "    lo, hi = -10.0, 10.0\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        mid = (lo+hi)/2\n",
    "        m = inv_logit(z + mid).mean()\n",
    "        \n",
    "        if abs(m - target_mean) < tol:\n",
    "            return inv_logit(z + mid)\n",
    "        \n",
    "        if m < target_mean:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    \n",
    "    print(\"Ostrzeżenie: Osiągnięto limit iteracji w wyszukiwaniu.\")\n",
    "    return inv_logit(z + (lo+hi)/2)\n",
    "\n",
    "\n",
    "proba_iso_pre_shift = y_proba_test_iso\n",
    "\n",
    "print(f\"Średnia prognoza (Isotonic, przed shiftem): {proba_iso_pre_shift.mean():.4f}\")\n",
    "\n",
    "target_pd_mean = 0.04\n",
    "print(f\"Rozpoczynam dostrajanie do średniej = {target_pd_mean}...\")\n",
    "proba_iso_4pct = shift_to_target_mean(proba_iso_pre_shift, target_mean=target_pd_mean)\n",
    "\n",
    "print(\"\\n--- OCENA (POST-SHIFT 4%) ---\")\n",
    "print(f\"Średnia po dostrojeniu: {proba_iso_4pct.mean():.4f} (Cel: {target_pd_mean})\")\n",
    "\n",
    "brier_4pct = brier_score_loss(y_test, proba_iso_4pct)\n",
    "ece_4pct = expected_calibration_error(y_test, proba_iso_4pct)\n",
    "\n",
    "print(f\"Brier (post-shift): {brier_4pct:.4f}\")\n",
    "print(f\"ECE (post-shift):   {ece_4pct:.4f}\")\n",
    "\n",
    "reliability_plot(y_test, proba_iso_4pct, f\"Reliability — Isotonic + Shift {target_pd_mean*100}% (test)\")\n",
    "hist_predictions(proba_iso_4pct, f\"Histogram — Isotonic + Shift {target_pd_mean*100}% (test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9cd75",
   "metadata": {},
   "source": [
    "---\n",
    "## `Macierz Kosztów Decyzyjnych`\n",
    "\n",
    "---\n",
    "\n",
    "Ten fragment kodu definiuje macierz kosztów dla problemu klasyfikacji binarnej, przypisuje wagę finansową (lub inną miarę straty) do każdego z czterech możliwych wyników predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4153c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "COST_TP = 0.0\n",
    "COST_FP = 1.0\n",
    "COST_FN = 18.0\n",
    "COST_TN = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dafdf9",
   "metadata": {},
   "source": [
    "---\n",
    "## `Funkcje Optymalizacji Kosztu Decyzyjnego`\n",
    "\n",
    "---\n",
    "\n",
    "Ten blok kodu definiuje dwie funkcje służące do obliczenia całkowitego kosztu podejmowanych decyzji w modelu klasyfikacji w oparciu o zdefiniowaną wcześniej macierz kosztów, a następnie do systematycznego przeszukiwania (sweep) różnych progów decyzyjnych w celu znalezienia progu minimalizującego ten koszt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_for_threshold(y_true, p, thr):\n",
    "    yhat = (p >= thr).astype(int)\n",
    "    \n",
    "    tp = np.sum((yhat==1) & (y_true==1))\n",
    "    fp = np.sum((yhat==1) & (y_true==0))\n",
    "    fn = np.sum((yhat==0) & (y_true==1))\n",
    "    tn = np.sum((yhat==0) & (y_true==0))\n",
    "    \n",
    "    total_cost = tp*COST_TP + fp*COST_FP + fn*COST_FN + tn*COST_TN\n",
    "    return total_cost, tp, fp, fn, tn\n",
    "\n",
    "def sweep_costs(y_true, p, n=201):\n",
    "    thrs = np.linspace(0,1,n)\n",
    "    costs, details = [], []\n",
    "    for t in thrs:\n",
    "        c, tp, fp, fn, tn = cost_for_threshold(y_true, p, t)\n",
    "        costs.append(c); details.append((tp,fp,fn,tn))\n",
    "    return thrs, np.array(costs), details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022cdb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c168d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_data = y_test\n",
    "p_data = proba_iso_4pct \n",
    "\n",
    "print(f\"Rozpoczynam analizę kosztów dla {len(p_data)} obserwacji...\")\n",
    "\n",
    "thrs, costs, details = sweep_costs(y_true_data, p_data, n=201)\n",
    "\n",
    "best_idx = int(np.argmin(costs))\n",
    "best_thr_cost = float(thrs[best_idx])\n",
    "best_cost = costs[best_idx]\n",
    "best_tp, best_fp, best_fn, best_tn = details[best_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thrs, costs, label='Całkowity koszt biznesowy')\n",
    "plt.axvline(x=best_thr_cost, color='red', linestyle='--', \n",
    "            label=f'Optymalny próg: {best_thr_cost:.4f}\\n(Min. koszt: {best_cost:.2f})')\n",
    "plt.title(\"Krzywa kosztu vs próg decyzyjny\")\n",
    "plt.xlabel(\"Próg decyzyjny (Odmów, jeśli PD >= Próg)\")\n",
    "plt.ylabel(\"Całkowity koszt (Im niżej, tym lepiej)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Wyniki Optymalnego Progu Biznesowego ---\")\n",
    "print(f\"Optymalny próg (minimalizujący koszt): {best_thr_cost:.4f}\")\n",
    "print(f\"Minimalny osiągnięty koszt: {best_cost:.2f}\")\n",
    "print(\"\\nMacierz pomyłek dla tego progu:\")\n",
    "print(f\"  Prawdziwie Pozytywni (TP - Odmówiono złym): {best_tp}\")\n",
    "print(f\"  Fałszywie Pozytywni (FP - Odmówiono dobrym): {best_fp}  (Koszt: {best_fp * COST_FP})\")\n",
    "print(f\"  Fałszywie Negatywni (FN - Udzielono złym):  {best_fn}  (Koszt: {best_fn * COST_FN})\")\n",
    "print(f\"  Prawdziwie Negatywni (TN - Udzielono dobrym): {best_tn}  (Zysk: {best_tn * COST_TN})\")\n",
    "\n",
    "accept_rate = (best_fn + best_tn) / len(y_true_data)\n",
    "print(f\"\\nStopa akceptacji (udzielono kredytu): {accept_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383c00d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3046ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_bins = [0.00, 0.045, 0.15, 1.01]\n",
    "\n",
    "rating_labels = [\n",
    "    \"A (Akceptacja)\", \n",
    "    \"B (Akceptacja lub analiza)\", \n",
    "    \"C (Odrzucenie)\"\n",
    "]\n",
    "\n",
    "def pd_to_rating(p, bins, labels):\n",
    "    return pd.cut(p, bins=bins, labels=labels, right=False, include_lowest=True)\n",
    "\n",
    "\n",
    "final_pd = proba_iso_4pct\n",
    "\n",
    "ratings = pd_to_rating(final_pd, rating_bins, rating_labels)\n",
    "\n",
    "print(\"--- Liczność klientów w każdej klasie ratingowej ---\")\n",
    "tab_licznosci = pd.crosstab(ratings, columns=\"Liczność klientów\")\n",
    "print(tab_licznosci)\n",
    "\n",
    "\n",
    "validation_df = pd.DataFrame({\n",
    "    'Rating': ratings,\n",
    "    'Predicted_PD': final_pd,\n",
    "    'Actual_Default': y_test\n",
    "})\n",
    "\n",
    "rating_summary = validation_df.groupby('Rating').agg(\n",
    "    Liczność=('Rating', 'count'),\n",
    "    Średnie_Prognozowane_PD=('Predicted_PD', 'mean'),\n",
    "    Rzeczywisty_Odsetek_Default=('Actual_Default', 'mean')\n",
    ")\n",
    "\n",
    "print(\"\\n--- Walidacja Monotoniczności Ratingów ---\")\n",
    "print(rating_summary)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "rating_summary['Rzeczywisty_Odsetek_Default'].plot(kind='bar', color='salmon')\n",
    "plt.title(\"Walidacja: Rzeczywisty % Defaultu vs Klasa Ratingowa\")\n",
    "plt.xlabel(\"Klasa Ratingowa\")\n",
    "plt.ylabel(\"Rzeczywisty Odsetek Defaultu (im wyżej, tym gorzej)\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "decision_table = rating_summary[['Średnie_Prognozowane_PD', 'Rzeczywisty_Odsetek_Default']].copy()\n",
    "\n",
    "decision_table['Sugerowana Decyzja Biznesowa'] = [\n",
    "    \"Akceptacja Automatyczna\", \n",
    "    \"Odrzucenie (lub Analiza Manualna)\",\n",
    "    \"Odrzucenie Automatyczne\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Finalna Tabela Decyzyjna / Mapa Ratingowa ---\")\n",
    "\n",
    "decision_table['Średnie_Prognozowane_PD'] = decision_table['Średnie_Prognozowane_PD'].map('{:.2%}'.format)\n",
    "decision_table['Rzeczywisty_Odsetek_Default'] = decision_table['Rzeczywisty_Odsetek_Default'].map('{:.2%}'.format)\n",
    "\n",
    "print(decision_table.to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
